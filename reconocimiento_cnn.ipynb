{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CEFab/redes-neuronales-notebooks/blob/main/reconocimiento_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpVgSST_Y455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0319fbbd-822c-4c17-ee33-4dca514c5777"
      },
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "Successfully installed keras-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsvzwGy-bWrT"
      },
      "source": [
        "# Clonamos el repositorio para obtener el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWYwSH-3Z97s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecab252a-7ce0-43c3-8562-a7f71aa5c76c"
      },
      "source": [
        "!git clone https://github.com/joanby/deeplearning-az.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning-az'...\n",
            "remote: Enumerating objects: 10295, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 10295 (delta 57), reused 50 (delta 39), pack-reused 10200 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10295/10295), 297.62 MiB | 32.65 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Updating files: 100% (20243/20243), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-fLk6oobhF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167c4c0f-065d-4996-e3f1-b9abb22ebadc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj7yYesKbctW"
      },
      "source": [
        "# Parte 1 - Construir el modelo de CNN\n",
        "\n",
        "# Importar las librerías y paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBacLjT1Y81H"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtczsRskbj2F"
      },
      "source": [
        "# Inicializar la CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQL9sTJ9Y_Vc"
      },
      "source": [
        "classifier = Sequential()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUbAgrrqbpsY"
      },
      "source": [
        "# Paso 1 - Convolución"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYdJsjsZCR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3ef6bb-d9ef-4a80-c69f-c67c47454d4d"
      },
      "source": [
        "classifier.add(Conv2D(filters = 32,kernel_size = (3, 3),\n",
        "                      input_shape = (64, 64, 3), activation = \"relu\"))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBFya76KbsKw"
      },
      "source": [
        "# Paso 2 - Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jty3bSFYZD98"
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgJ4s9fSb8bm"
      },
      "source": [
        "# Una segunda capa de convolución y max pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkVuO25YZHtg"
      },
      "source": [
        "classifier.add(Conv2D(filters = 32,kernel_size = (3, 3), activation = \"relu\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rd5DVFZIWb"
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfacNAkPb_T-"
      },
      "source": [
        "# Paso 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWl9_DHxZJZD"
      },
      "source": [
        "classifier.add(Flatten())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksz0Q4WGcB77"
      },
      "source": [
        "# Paso 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQnTQSjyZKXs"
      },
      "source": [
        "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
        "classifier.add(Dense(units = 1, activation = \"sigmoid\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7INHvHmcFdL"
      },
      "source": [
        "# Compilar la CNN\n",
        "# Como va a ser entrenada?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc7pBop7ZLeN"
      },
      "source": [
        "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ9CtO8QT4Z6",
        "outputId": "7739ac71-90bd-4de4-e979-07c9ca20929c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 May 24 04:58 single_prediction\n",
            "drwxr-xr-x 4 root root 4096 May 24 04:58 test_set\n",
            "drwxr-xr-x 4 root root 4096 May 24 04:58 training_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hits0FnccMjr"
      },
      "source": [
        "# Parte 2 - Ajustar la CNN a las imágenes para entrenar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYgCwVDFZMrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b97c725-70fd-4445-bc21-b7a0f67fca0e"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_dataset = train_datagen.flow_from_directory('/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set',\n",
        "                                                    target_size=(64, 64),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "testing_dataset = test_datagen.flow_from_directory('/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set',\n",
        "                                                target_size=(64, 64),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='binary')\n",
        "\n",
        "classifier.fit(training_dataset,\n",
        "                        steps_per_epoch=len(training_dataset),\n",
        "                        epochs=25,\n",
        "                        validation_data=testing_dataset,\n",
        "                        validation_steps=len(testing_dataset))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - accuracy: 0.7823 - loss: 0.4610 - val_accuracy: 0.7890 - val_loss: 0.4706\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.7911 - loss: 0.4465 - val_accuracy: 0.7870 - val_loss: 0.4628\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - accuracy: 0.8009 - loss: 0.4232 - val_accuracy: 0.7925 - val_loss: 0.4639\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 89ms/step - accuracy: 0.8140 - loss: 0.4031 - val_accuracy: 0.8070 - val_loss: 0.4426\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - accuracy: 0.8229 - loss: 0.3937 - val_accuracy: 0.7995 - val_loss: 0.4480\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.8266 - loss: 0.3824 - val_accuracy: 0.7690 - val_loss: 0.4965\n",
            "Epoch 7/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - accuracy: 0.8307 - loss: 0.3787 - val_accuracy: 0.7970 - val_loss: 0.4637\n",
            "Epoch 8/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.8423 - loss: 0.3430 - val_accuracy: 0.8060 - val_loss: 0.4475\n",
            "Epoch 9/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - accuracy: 0.8544 - loss: 0.3343 - val_accuracy: 0.8045 - val_loss: 0.4532\n",
            "Epoch 10/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - accuracy: 0.8474 - loss: 0.3351 - val_accuracy: 0.8120 - val_loss: 0.4413\n",
            "Epoch 11/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - accuracy: 0.8558 - loss: 0.3237 - val_accuracy: 0.8110 - val_loss: 0.4392\n",
            "Epoch 12/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 92ms/step - accuracy: 0.8577 - loss: 0.3199 - val_accuracy: 0.8155 - val_loss: 0.4541\n",
            "Epoch 13/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.8689 - loss: 0.3022 - val_accuracy: 0.7990 - val_loss: 0.4985\n",
            "Epoch 14/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.8779 - loss: 0.2908 - val_accuracy: 0.7970 - val_loss: 0.4720\n",
            "Epoch 15/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.8851 - loss: 0.2684 - val_accuracy: 0.8070 - val_loss: 0.4589\n",
            "Epoch 16/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.8830 - loss: 0.2811 - val_accuracy: 0.8100 - val_loss: 0.4825\n",
            "Epoch 17/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - accuracy: 0.9022 - loss: 0.2441 - val_accuracy: 0.8045 - val_loss: 0.4954\n",
            "Epoch 18/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 97ms/step - accuracy: 0.9008 - loss: 0.2319 - val_accuracy: 0.7945 - val_loss: 0.5288\n",
            "Epoch 19/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.9003 - loss: 0.2384 - val_accuracy: 0.8115 - val_loss: 0.4888\n",
            "Epoch 20/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - accuracy: 0.9095 - loss: 0.2191 - val_accuracy: 0.8145 - val_loss: 0.4972\n",
            "Epoch 21/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - accuracy: 0.9142 - loss: 0.2064 - val_accuracy: 0.8015 - val_loss: 0.5391\n",
            "Epoch 22/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 85ms/step - accuracy: 0.9091 - loss: 0.2136 - val_accuracy: 0.8040 - val_loss: 0.5370\n",
            "Epoch 23/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.9119 - loss: 0.2179 - val_accuracy: 0.8000 - val_loss: 0.5777\n",
            "Epoch 24/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 88ms/step - accuracy: 0.9192 - loss: 0.1918 - val_accuracy: 0.8080 - val_loss: 0.5613\n",
            "Epoch 25/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step - accuracy: 0.9220 - loss: 0.1929 - val_accuracy: 0.7985 - val_loss: 0.5784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cbc6022c050>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar modelo entrenado"
      ],
      "metadata": {
        "id": "x3eQzZ3MmgKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ra opcion: formato .h5\n",
        "# Guardar el modelo en Google Drive\n",
        "classifier.save('/content/drive/MyDrive/modelo_entrenado.h5')  # Formato HDF5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FIxfvzHj_qO",
        "outputId": "04b90654-4e77-4bd2-c393-8a64a213d98d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2da opcion: formato .keras\n",
        "# Guardar el modelo en formato .keras (recomendado)\n",
        "classifier.save('/content/drive/MyDrive/modelo_entrenado.keras')"
      ],
      "metadata": {
        "id": "vD6FFpcKkuMs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwHuYDWfcPEZ"
      },
      "source": [
        "# Parte 3 - Cómo hacer nuevas predicciones"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ra opcion: Con modelo recien entrenado"
      ],
      "metadata": {
        "id": "brDtYsJ2m8cO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7k7KG9SZOjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf7448b-5487-4619-abe5-9b342c415f46"
      },
      "source": [
        "# 1ra opcion, modelo recien entrenado\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image  # Corrige la importación\n",
        "\n",
        "# Cargar la imagen\n",
        "test_image = image.load_img(\n",
        "    '/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_2.jpg',\n",
        "    target_size=(64, 64)\n",
        ")\n",
        "\n",
        "# Preprocesamiento\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0) / 255.0  # Normaliza (¡importante!)\n",
        "\n",
        "# Predicción\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "# Obtener las clases (asegúrate de que training_dataset está definido)\n",
        "class_labels = list(training_dataset.class_indices.keys())  # Ej: ['cats', 'dogs']\n",
        "\n",
        "# Determinar la clase\n",
        "predicted_class = class_labels[int(result[0][0] > 0.5)]  # Umbral 0.5 para binario\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"Predicción:\", predicted_class)\n",
        "print(\"Confianza:\", result[0][0] if predicted_class == 'dog' else 1 - result[0][0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step\n",
            "Predicción: cats\n",
            "Confianza: 0.8156208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2da opcion: Con modelo guardado"
      ],
      "metadata": {
        "id": "_k-HyewunC_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model  # Importar load_model\n",
        "\n",
        "# 1. Cargar el modelo guardado\n",
        "modelo_cargado = load_model('/content/drive/MyDrive/modelo_entrenado.keras')  # Ruta correcta\n"
      ],
      "metadata": {
        "id": "VcMXpewBlSyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81023532-988f-4282-ce4e-362b9032e98b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Cargar y preprocesar la imagen (igual que antes)\n",
        "test_image = image.load_img(\n",
        "    '/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_2.jpg',\n",
        "    target_size=(64, 64)\n",
        ")\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0) / 255.0  # Normalizar\n",
        "\n",
        "# 3. Hacer la predicción con el modelo cargado\n",
        "result = modelo_cargado.predict(test_image)  # Usar modelo_cargado, no classifier\n",
        "\n",
        "# 4. Obtener clases y resultado (asegúrate de tener training_dataset definido)\n",
        "class_labels = list(training_dataset.class_indices.keys())\n",
        "predicted_class = class_labels[int(result[0][0] > 0.5)]\n",
        "confianza = result[0][0] if predicted_class == 'dog' else 1 - result[0][0]\n",
        "\n",
        "print(\"Predicción:\", predicted_class)\n",
        "print(\"Confianza:\", confianza)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn2aICaVliXl",
        "outputId": "ea3a22d7-a9ed-4106-ea52-d9ee3fbaca8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicción: cats\n",
            "Confianza: 0.8156208\n"
          ]
        }
      ]
    }
  ]
}