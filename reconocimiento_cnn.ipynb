{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CEFab/redes-neuronales-notebooks/blob/main/reconocimiento_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpVgSST_Y455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413c688e-c624-4cf6-9624-3e0e1d12bb76"
      },
      "source": [
        "pip install --upgrade keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "Successfully installed keras-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsvzwGy-bWrT"
      },
      "source": [
        "# Clonamos el repositorio para obtener el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWYwSH-3Z97s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee04bbd-6caf-4386-8562-52fe495b3250"
      },
      "source": [
        "!git clone https://github.com/joanby/deeplearning-az.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning-az'...\n",
            "remote: Enumerating objects: 10295, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 10295 (delta 56), reused 49 (delta 38), pack-reused 10201 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10295/10295), 297.62 MiB | 38.46 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Updating files: 100% (20243/20243), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-fLk6oobhF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a825c9-2495-4c23-cc1c-614796b8d520"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj7yYesKbctW"
      },
      "source": [
        "# Parte 1 - Construir el modelo de CNN\n",
        "\n",
        "# Importar las librerías y paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBacLjT1Y81H"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtczsRskbj2F"
      },
      "source": [
        "# Inicializar la CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQL9sTJ9Y_Vc"
      },
      "source": [
        "classifier = Sequential()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUbAgrrqbpsY"
      },
      "source": [
        "# Paso 1 - Convolución"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kYdJsjsZCR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd4bc13-e9b4-482e-f1dc-780138035a57"
      },
      "source": [
        "classifier.add(Conv2D(filters = 32,kernel_size = (3, 3),\n",
        "                      input_shape = (64, 64, 3), activation = \"relu\"))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBFya76KbsKw"
      },
      "source": [
        "# Paso 2 - Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jty3bSFYZD98"
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgJ4s9fSb8bm"
      },
      "source": [
        "# Una segunda capa de convolución y max pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkVuO25YZHtg"
      },
      "source": [
        "classifier.add(Conv2D(filters = 32,kernel_size = (3, 3), activation = \"relu\"))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rd5DVFZIWb"
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfacNAkPb_T-"
      },
      "source": [
        "# Paso 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWl9_DHxZJZD"
      },
      "source": [
        "classifier.add(Flatten())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksz0Q4WGcB77"
      },
      "source": [
        "# Paso 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQnTQSjyZKXs"
      },
      "source": [
        "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
        "classifier.add(Dense(units = 1, activation = \"sigmoid\"))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7INHvHmcFdL"
      },
      "source": [
        "# Compilar la CNN\n",
        "# Como va a ser entrenada?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc7pBop7ZLeN"
      },
      "source": [
        "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ9CtO8QT4Z6",
        "outputId": "2f6be6cd-3919-4a7a-ef0c-4b1fb7faf99d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 May 23 03:51 single_prediction\n",
            "drwxr-xr-x 4 root root 4096 May 23 03:51 test_set\n",
            "drwxr-xr-x 4 root root 4096 May 23 03:51 training_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hits0FnccMjr"
      },
      "source": [
        "# Parte 2 - Ajustar la CNN a las imágenes para entrenar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYgCwVDFZMrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08902dea-be3e-41a8-b7e4-009f1c41dab6"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_dataset = train_datagen.flow_from_directory('/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set',\n",
        "                                                    target_size=(64, 64),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "testing_dataset = test_datagen.flow_from_directory('/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set',\n",
        "                                                target_size=(64, 64),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='binary')\n",
        "\n",
        "classifier.fit(training_dataset,\n",
        "                        steps_per_epoch=8000,\n",
        "                        epochs=25,\n",
        "                        validation_data=testing_dataset,\n",
        "                        validation_steps=2000)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m 250/8000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:06\u001b[0m 78ms/step - accuracy: 0.5635 - loss: 0.6752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.6128 - loss: 0.6466 - val_accuracy: 0.6830 - val_loss: 0.5830\n",
            "Epoch 2/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.5797 - val_accuracy: 0.7225 - val_loss: 0.5427\n",
            "Epoch 3/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5396 - val_accuracy: 0.6995 - val_loss: 0.5932\n",
            "Epoch 4/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.5000 - val_accuracy: 0.7595 - val_loss: 0.4980\n",
            "Epoch 5/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4836 - val_accuracy: 0.7770 - val_loss: 0.4598\n",
            "Epoch 6/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.4672 - val_accuracy: 0.7225 - val_loss: 0.5619\n",
            "Epoch 7/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4533 - val_accuracy: 0.7865 - val_loss: 0.4505\n",
            "Epoch 8/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4424 - val_accuracy: 0.7995 - val_loss: 0.4438\n",
            "Epoch 9/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4222 - val_accuracy: 0.7510 - val_loss: 0.5356\n",
            "Epoch 10/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.4176 - val_accuracy: 0.7930 - val_loss: 0.4606\n",
            "Epoch 11/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8187 - loss: 0.3952 - val_accuracy: 0.8005 - val_loss: 0.4616\n",
            "Epoch 12/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.8187 - loss: 0.3934 - val_accuracy: 0.7995 - val_loss: 0.4475\n",
            "Epoch 13/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.3737 - val_accuracy: 0.7930 - val_loss: 0.4585\n",
            "Epoch 14/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3697 - val_accuracy: 0.8050 - val_loss: 0.4329\n",
            "Epoch 15/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3545 - val_accuracy: 0.7590 - val_loss: 0.5222\n",
            "Epoch 16/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.3395 - val_accuracy: 0.7730 - val_loss: 0.5279\n",
            "Epoch 17/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3285 - val_accuracy: 0.8025 - val_loss: 0.4435\n",
            "Epoch 18/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3175 - val_accuracy: 0.7905 - val_loss: 0.5191\n",
            "Epoch 19/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.3074 - val_accuracy: 0.8085 - val_loss: 0.4855\n",
            "Epoch 20/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.2946 - val_accuracy: 0.8230 - val_loss: 0.4830\n",
            "Epoch 21/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2748 - val_accuracy: 0.7925 - val_loss: 0.4890\n",
            "Epoch 22/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.2729 - val_accuracy: 0.8025 - val_loss: 0.4831\n",
            "Epoch 23/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.2569 - val_accuracy: 0.7975 - val_loss: 0.5266\n",
            "Epoch 24/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2432 - val_accuracy: 0.8080 - val_loss: 0.4946\n",
            "Epoch 25/25\n",
            "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.2378 - val_accuracy: 0.8115 - val_loss: 0.4873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bf3f37c3f90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwHuYDWfcPEZ"
      },
      "source": [
        "# Parte 3 - Cómo hacer nuevas predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7k7KG9SZOjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446b21c5-56b4-4512-897e-6310b87e7130"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image  # Corrige la importación\n",
        "\n",
        "# Cargar la imagen\n",
        "test_image = image.load_img(\n",
        "    '/content/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_3.jpg',\n",
        "    target_size=(64, 64)\n",
        ")\n",
        "\n",
        "# Preprocesamiento\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0) / 255.0  # Normaliza (¡importante!)\n",
        "\n",
        "# Predicción\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "# Obtener las clases (asegúrate de que training_dataset está definido)\n",
        "class_labels = list(training_dataset.class_indices.keys())  # Ej: ['cats', 'dogs']\n",
        "\n",
        "# Determinar la clase\n",
        "predicted_class = class_labels[int(result[0][0] > 0.5)]  # Umbral 0.5 para binario\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"Predicción:\", predicted_class)\n",
        "print(\"Confianza:\", result[0][0] if predicted_class == 'dog' else 1 - result[0][0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Predicción: cats\n",
            "Confianza: 0.52658397\n"
          ]
        }
      ]
    }
  ]
}